{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the inferences from the previous part, the data set will be taken without two columns, namely, 'Time' and 'Amount'. Feature creation is hard as the nature and interaction of attributes is not given and hence that step will be passed at this time. In this notebook, a baseline model will be done after test/train split.\n",
    "(Reference: https://machinelearningmastery.com/imbalanced-classification-with-the-fraudulent-credit-card-transactions-dataset/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from numpy import mean\n",
    "from scipy.stats import sem\n",
    "from scipy.stats import t\n",
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard 2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf = df.drop(['Time'], axis = 1)\n",
    "myccdf = mydf.drop('Amount', axis = 1)\n",
    "y = myccdf['Class']\n",
    "myccdf = myccdf.drop('Class', axis = 1)\n",
    "X = myccdf\n",
    "y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V19       V20       V21       V22  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.403993  0.251412 -0.018307  0.277838   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.145783 -0.069083 -0.225775 -0.638672   \n",
       "2  0.247676 -1.514654  0.207643  ... -2.261857  0.524980  0.247998  0.771679   \n",
       "3  0.377436 -1.387024 -0.054952  ... -1.232622 -0.208038 -0.108300  0.005274   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.803487  0.408542 -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X and y are used now for the rest of the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, multi_class='ovr', random_state=0,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test/train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression(solver='liblinear'\n",
    "                            , C=10.0, multi_class='ovr',\n",
    "                           random_state=0)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 1.00\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85285    11]\n",
      " [   56    91]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.89      0.62      0.73       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.95      0.81      0.87     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "0.9681099320238318\n",
      "AUC for Logistic Regression:  0.7677551007740622\n"
     ]
    }
   ],
   "source": [
    "p_pred = logreg.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "class1_probs = p_pred[:, 1]\n",
    "y_pred = logreg.predict(X_test)\n",
    "score_ = logreg.score(X_test, y_test)\n",
    "conf_m_nr = confusion_matrix(y_test, y_pred)\n",
    "report_nr = classification_report(y_test, y_pred)\n",
    "precision, recall, _ = precision_recall_curve(y_test, class1_probs)\n",
    "f1_nr, auc_nr = f1_score(y_test, y_pred), auc(recall, precision)\n",
    "roc_auc_nr = roc_auc_score(y_test, class1_probs)\n",
    "print(conf_m_nr)\n",
    "print(report_nr)\n",
    "print(roc_auc_nr)\n",
    "print(\"AUC for Logistic Regression: \",auc_nr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while F1 score is 1.00 and accuracy is also 1, AUC (Area under the Curve) is th ebest estimate for an imbalanced dataset. Taking the probabilities for the minority class ( class = 1) , AUC is .7678. It suggests for improvement by leveraging other models like Random Forest andn neural networks and sampling techniques like SMOTE, and acronym for Synthetic Minority Oversampling Technique. It is part of imblearn library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing SMOTE for minority oversampling. \n",
    "#Oversamppling is olny applied to training data\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#Oversampling the data\n",
    "smote = SMOTE(random_state = 101)\n",
    "X_oversample, y_oversample = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     85296\n",
      "           1       0.06      0.92      0.11       147\n",
      "\n",
      "    accuracy                           0.98     85443\n",
      "   macro avg       0.53      0.95      0.55     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_o = LogisticRegression()\n",
    "classifier_o.fit(X_oversample, y_oversample)\n",
    "print(classification_report(y_test, classifier_o.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set with oversampled training: 1.00\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier_o.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set with oversampled training: {:.2f}'.format(logreg.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pred =  classifier_o.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "class1_probs = p_pred[:, 1]\n",
    "y_pred =  classifier_o.predict(X_test)\n",
    "score_ =  classifier_o.score(X_test, y_test)\n",
    "conf_m_o = confusion_matrix(y_test, y_pred)\n",
    "report_o = classification_report(y_test, y_pred)\n",
    "precision_o, recall_o, _ = precision_recall_curve(y_test, class1_probs)\n",
    "f1_o = f1_score(y_test, y_pred)\n",
    "auc_o =  auc(recall_o, precision_o)\n",
    "roc_auc_o = roc_auc_score(y_test, class1_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83201  2095]\n",
      " [   12   135]]\n"
     ]
    }
   ],
   "source": [
    "print(conf_m_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for Logistic Regression with oversampoling using SMOTE:  0.767793241256793\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC for Logistic Regression with oversampoling using SMOTE: \",auc_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9829752126887146\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WIth th emetric being AUC as the chosen metric for imbalanced data sets, there is only a very small improvement with SMOTE over normal random sampling with logistic regression as modelling methoid.\n",
    "0.7677551007740622 vs 0.767793241256793"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out RandomForest with normal sampling to findn the most useful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "importances = rfc.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01326846 0.00982796 0.01029522 0.02207807 0.01264187 0.01488068\n",
      " 0.01716239 0.01263355 0.0151335  0.04174037 0.10428165 0.05014706\n",
      " 0.01292686 0.11635846 0.01568078 0.06419459 0.27484529 0.06807631\n",
      " 0.0157938  0.01500941 0.00959757 0.0077592  0.00601102 0.00913243\n",
      " 0.01430109 0.02910649 0.009832   0.00728391]\n"
     ]
    }
   ],
   "source": [
    "print(importances)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col_importances = pd.DataFrame(importances, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 28 entries, V1 to V28\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       28 non-null     float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 1.5+ KB\n"
     ]
    }
   ],
   "source": [
    "col_importances.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>0.013268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>0.009828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>0.010295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>0.022078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>0.012642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "V1  0.013268\n",
       "V2  0.009828\n",
       "V3  0.010295\n",
       "V4  0.022078\n",
       "V5  0.012642"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_importances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cols = col_importances[col_importances[0]>0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>0.104282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>0.050147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>0.116358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>0.064195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>0.274845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>0.068076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "V11  0.104282\n",
       "V12  0.050147\n",
       "V14  0.116358\n",
       "V16  0.064195\n",
       "V17  0.274845\n",
       "V18  0.068076"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection of more important featues (importance > .05)\n",
    "may help improve the model performance. With that notion, a subset of predictor variables are taken from training and test datasets. To differentiate the subset, a suffix, '-n',  is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n = X_train[['V11','V12', 'V14','V16','V17','V18']]\n",
    "X_test_n = X_test[['V11','V12', 'V14','V16','V17','V18']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n.head()\n",
    "X_test_n.head()\n",
    "y_train_n = y_train\n",
    "y_test_n = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using minority oversampling with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n_os, y_train_n_os = smote.fit_resample(X_train_n, y_train_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995452695471287\n",
      "Train ROC AUC Score for Oversampling minority: 1.0\n",
      "Test ROC AUC  Score: 0.9561945627997963\n",
      "[[85239    57]\n",
      " [   29   118]]\n",
      "AUC for oversampling: 0.7778003533619295\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42, oob_score=True)\n",
    "rfc.fit(X_train_n_os, y_train_n_os)\n",
    "\n",
    "from sklearn import metrics\n",
    "pred_train_os = np.argmax(rfc.oob_decision_function_,axis=1)\n",
    "print(metrics.roc_auc_score(y_train_n_os, pred_train_os))\n",
    "y_pred_n = rfc.predict(X_test_n)\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, roc_auc_score, roc_curve, f1_score\n",
    "accuracy_score(y_test_n, y_pred_n)\n",
    "train_probs = rfc.predict_proba(X_train_n_os)[:,1] \n",
    "probs = rfc.predict_proba(X_test_n)[:, 1]\n",
    "train_predictions = rfc.predict(X_train_n_os)\n",
    "print(f'Train ROC AUC Score for Oversampling minority: {roc_auc_score(y_train_n_os, train_probs)}')\n",
    "print(f'Test ROC AUC  Score: {roc_auc_score(y_test_n, probs)}')\n",
    "cm = confusion_matrix(y_test_n, y_pred_n)\n",
    "print(cm)\n",
    "precision_n_os, recall_n_os, _ = precision_recall_curve(y_test_n, probs)\n",
    "f1_n_os, auc_n_os = f1_score(y_test_n, y_pred_n), auc(recall_n_os, precision_n_os)\n",
    "print(\"AUC for oversampling:\",auc_n_os)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting undersampling for the majority class (Class = 0) now.\n",
    "(REF. : https://www.kaggle.com/residentmario/advanced-under-sampling-and-data-cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "enn = EditedNearestNeighbours()\n",
    "X_train_n_enn, y_train_n_enn = enn.fit_resample(X_train_n, y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(oob_score=True, random_state=42)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_enn = RandomForestClassifier(n_estimators=100, random_state=42, oob_score=True)\n",
    "rfc_enn.fit(X_train_n_enn, y_train_n_enn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8999723416559805\n"
     ]
    }
   ],
   "source": [
    "pred_train_enn = np.argmax(rfc_enn.oob_decision_function_,axis=1)\n",
    "print(metrics.roc_auc_score(y_train_n_enn, pred_train_enn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC Score for undesampling majority: 1.0\n",
      "Test ROC AUC  Score : 0.9235698382710802\n",
      "[[85278    18]\n",
      " [   35   112]]\n",
      "AUC for undersampling with ENN technique and RFC:  0.7789158948343924\n"
     ]
    }
   ],
   "source": [
    "y_pred_n_enn = rfc_enn.predict(X_test_n)\n",
    "accuracy_score(y_test_n, y_pred_n_enn)\n",
    "train_probs_enn = rfc_enn.predict_proba(X_train_n_enn)[:,1] \n",
    "probs_enn = rfc_enn.predict_proba(X_test_n)[:, 1]\n",
    "train_predictions_enn = rfc_enn.predict(X_train_n_enn)\n",
    "print(f'Train ROC AUC Score for undesampling majority: {roc_auc_score(y_train_n_enn, train_probs_enn)}')\n",
    "print(f'Test ROC AUC  Score : {roc_auc_score(y_test_n, probs_enn)}')\n",
    "cm_enn = confusion_matrix(y_test_n, y_pred_n_enn)\n",
    "print(cm_enn)\n",
    "precision_n_enn, recall_n_enn, _ = precision_recall_curve(y_test_n, probs_enn)\n",
    "f1_n_enn, auc_n_enn = f1_score(y_test_n, y_pred_n_enn), auc(recall_n_enn, precision_n_enn)\n",
    "print(\"AUC for undersampling with ENN technique and RFC: \",auc_n_enn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample = TomekLinks( )\n",
    "#X_tl, y_tl, id_tl = tl.fit_sample(X, y)\n",
    "#undersample = NearMiss(version=1, n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n_us, y_train_n_us = undersample.fit_resample(X_train_n, y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8811066551450022\n",
      "Train ROC AUC Score for undesampling majority: 1.0\n",
      "Test ROC AUC  Score : 0.9270555788438055\n",
      "[[85288     8]\n",
      " [   40   107]]\n",
      "AUC for undersampling with TomekLinks and RFC:  0.7997156183990267\n"
     ]
    }
   ],
   "source": [
    "rfc_us = RandomForestClassifier(n_estimators=100, random_state=42, oob_score=True)\n",
    "rfc_us.fit(X_train_n_us, y_train_n_us)\n",
    "\n",
    "pred_train_us = np.argmax(rfc_us.oob_decision_function_,axis=1)\n",
    "print(metrics.roc_auc_score(y_train_n_us, pred_train_us))\n",
    "\n",
    "y_pred_n_us = rfc_us.predict(X_test_n)\n",
    "accuracy_score(y_test_n, y_pred_n_us)\n",
    "train_probs_us = rfc_us.predict_proba(X_train_n_us)[:,1] \n",
    "probs_us = rfc_us.predict_proba(X_test_n)[:, 1]\n",
    "train_predictions_us = rfc_us.predict(X_train_n_us)\n",
    "print(f'Train ROC AUC Score for undesampling majority: {roc_auc_score(y_train_n_us, train_probs_us)}')\n",
    "print(f'Test ROC AUC  Score : {roc_auc_score(y_test_n, probs_us)}')\n",
    "cm_us = confusion_matrix(y_test_n, y_pred_n_us)\n",
    "print(cm_us)\n",
    "precision_n_us, recall_n_us, _ = precision_recall_curve(y_test_n, probs_us)\n",
    "f1_n_us, auc_n_us = f1_score(y_test_n, y_pred_n_us), auc(recall_n_us, precision_n_us)\n",
    "print(\"AUC for undersampling with TomekLinks and RFC: \",auc_n_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining oversampling  and undersampling in RFC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the SMOTEENN.\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# create the  object with the desired samplig strategy.\n",
    "smoenn = SMOTEENN(sampling_strategy='minority')\n",
    "\n",
    "# fit the object to our training data.\n",
    "X_train_smtenn, y_train_smtenn = smoenn.fit_resample(X_train_n, y_train_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998359770946955\n",
      "Train ROC AUC Score for undesampling majority: 1.0\n",
      "Test ROC AUC  Score : 0.9535464415554256\n",
      "[[85206    90]\n",
      " [   27   120]]\n",
      "AUC for sampling with SMTENN:  0.7673083800387608\n"
     ]
    }
   ],
   "source": [
    "rfc_smtenn = RandomForestClassifier(n_estimators=100, random_state=42, oob_score=True)\n",
    "rfc_smtenn.fit(X_train_smtenn, y_train_smtenn)\n",
    "\n",
    "pred_train_smtenn = np.argmax(rfc_smtenn.oob_decision_function_,axis=1)\n",
    "print(metrics.roc_auc_score(y_train_smtenn, pred_train_smtenn))\n",
    "\n",
    "y_pred_smtenn = rfc_smtenn.predict(X_test_n)\n",
    "accuracy_score(y_test_n, y_pred_smtenn)\n",
    "train_probs_smtenn = rfc_smtenn.predict_proba(X_train_smtenn)[:,1] \n",
    "probs_smtenn = rfc_smtenn.predict_proba(X_test_n)[:, 1]\n",
    "train_predictions_smtenn = rfc_smtenn.predict(X_train_smtenn)\n",
    "print(f'Train ROC AUC Score for undesampling majority: {roc_auc_score(y_train_smtenn, train_probs_smtenn)}')\n",
    "print(f'Test ROC AUC  Score : {roc_auc_score(y_test_n, probs_smtenn)}')\n",
    "cm_smtenn = confusion_matrix(y_test_n, y_pred_smtenn)\n",
    "print(cm_smtenn)\n",
    "precision_smtenn, recall_smtenn, _ = precision_recall_curve(y_test_n, probs_smtenn)\n",
    "f1_smtenn, auc_smtenn = f1_score(y_test_n, y_pred_smtenn), auc(recall_smtenn, precision_smtenn)\n",
    "print(\"AUC for sampling with SMTENN: \",auc_smtenn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there is some improvement in AUC with undersampling and feature selection compared to ovesampling or combined oversampling and undersampling. Also Tomeklinks undersampling ( AUC = 0.7997156183990267) better in this dataset than ENN.\n",
    "(Ref: https://www.kdnuggets.com/2020/01/classify-rare-event-machine-learning-algorithms.html). \n",
    "An attempt for  KNN will be tried now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn15 = KNeighborsClassifier(n_neighbors = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=15)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consider undersampled training set\n",
    "knn15.fit(X_train_n_us,y_train_n_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN results for  n_neighbors = 15\n",
      "[[85283    13]\n",
      " [   45   102]]\n",
      "0.9214596596470138\n",
      "AUC for KNN n = 15:  0.8088955930868675\n"
     ]
    }
   ],
   "source": [
    "y_pred_knn15 = knn15.predict(X_test_n)\n",
    "cm15 = confusion_matrix(y_test_n,y_pred_knn15)\n",
    "probs_knn15 = knn15.predict_proba(X_test_n)[:, 1]\n",
    "precision_knn15, recall_knn15, _ = precision_recall_curve(y_test_n, probs_knn15)\n",
    "f1_knn15, auc_knn15 = f1_score(y_test_n, y_pred_knn15), auc(recall_knn15, precision_knn15)\n",
    "\n",
    "roc_auc_acore_knn15 = roc_auc_score(y_test_n,probs_knn15)\n",
    "\n",
    "print(\"KNN results for  n_neighbors = 15\")\n",
    "print(cm15)\n",
    "print(roc_auc_acore_knn15 )\n",
    "print(\"AUC for KNN n = 15: \",auc_knn15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In case of classifier like knn the parameter to be tuned is n_neighbors\n",
    "param_grid = {'n_neighbors':np.arange(1,50)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_cv= GridSearchCV(knn,param_grid,cv=5)\n",
    "knn_cv.fit(X_train_n_us,y_train_n_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995284438647536"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 3}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN results for  n_neighbors = 3\n",
      "[[85290     6]\n",
      " [   37   110]]\n",
      "ROC_ AUC Score:  0.9080612595816793\n",
      "AUC:  0.8521320928776908\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train_n_us,y_train_n_us)\n",
    "y_pred_knn = knn.predict(X_test_n)\n",
    "cm_knn = confusion_matrix(y_test_n,y_pred_knn)\n",
    "probs_knn = knn.predict_proba(X_test_n)[:,1]\n",
    "roc_auc_score_knn = roc_auc_score(y_test_n,probs_knn)\n",
    "precision_knn, recall_knn, _ = precision_recall_curve(y_test_n, probs_knn)\n",
    "f1_knn, auc_knn = f1_score(y_test_n, y_pred_knn), auc(recall_knn, precision_knn)\n",
    "\n",
    "print(\"KNN results for  n_neighbors = 3\")\n",
    "\n",
    "print(cm_knn)\n",
    "print(\"ROC_ AUC Score: \",roc_auc_score_knn )\n",
    "print(\"AUC: \",auc_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "KNN(n = 3) with undersampling resulted in an AUC of 0.8521320928776908\n",
    "and it is indeed better than Randomforest Classifier with underrsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude with the usual classification techniques so far, KNN performed better than Random Forest and logistic regression. Under sampling of majority class proved to be bettter than oversampling of minority class or combined over and under sampling.\n",
    "The specific algorithms for imbalanced data are also worth exploring in the future iterationsn of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
